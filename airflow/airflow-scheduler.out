Starting flask
 * Serving Flask app "airflow.utils.serve_logs" (lazy loading)
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: off
[[34m2021-05-26 06:09:56,232[0m] {[34mscheduler_job.py:[0m1253} INFO[0m - Starting the scheduler[0m
[[34m2021-05-26 06:09:56,233[0m] {[34mscheduler_job.py:[0m1258} INFO[0m - Processing each file at most -1 times[0m
[[34m2021-05-26 06:09:56,240[0m] {[34mdag_processing.py:[0m254} INFO[0m - Launched DagFileProcessorManager with pid: 16420[0m
[[34m2021-05-26 06:09:56,242[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 06:09:56,258[0m] {[34msettings.py:[0m52} INFO[0m - Configured default timezone Timezone('UTC')[0m
[2021-05-26 06:09:56,273] {dag_processing.py:532} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2 ) when using sqlite. So we set parallelism to 1.
[[34m2021-05-26 06:14:56,327[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 06:19:56,378[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 06:24:54,852[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 3 tasks up for execution:
	<TaskInstance: my_simple_dag.say_Hi 2021-05-26 06:21:54.418538+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2021-05-26 06:22:57.868056+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 10:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:24:54,857[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 3 task instances ready to be queued[0m
[[34m2021-05-26 06:24:54,858[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:24:54,860[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:24:54,862[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 2/16 running and queued tasks[0m
[[34m2021-05-26 06:24:54,863[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 10:00:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2021-05-26 06:21:54.418538+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2021-05-26 06:22:57.868056+00:00 [scheduled]>[0m
[[34m2021-05-26 06:24:54,869[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 10, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:24:54,869[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T10:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:24:54,870[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2021, 5, 26, 6, 21, 54, 418538, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:24:54,870[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2021-05-26T06:21:54.418538+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:24:54,870[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2021, 5, 26, 6, 22, 57, 868056, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:24:54,871[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2021-05-26T06:22:57.868056+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:24:54,883[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T10:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:24:56,193[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T10:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:24:56,903[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2021-05-26T06:21:54.418538+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:24:58,461[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2021-05-26T06:21:54.418538+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:24:59,164[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2021-05-26T06:22:57.868056+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:00,501[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2021-05-26T06:22:57.868056+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:01,244[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 10:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:01,245[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2021-05-26 06:21:54.418538+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:01,245[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2021-05-26 06:22:57.868056+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:01,324[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 06:25:01,342[0m] {[34mscheduler_job.py:[0m1889} INFO[0m - Reset the following 3 orphaned TaskInstances:
	<TaskInstance: my_simple_dag.greet 2021-05-26 06:21:54.418538+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2021-05-26 06:22:57.868056+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:01,655[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 4 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2021-05-26 06:21:54.418538+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2021-05-26 06:22:57.868056+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:00:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 10:10:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:01,667[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 4 task instances ready to be queued[0m
[[34m2021-05-26 06:25:01,669[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:25:01,670[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:25:01,676[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 2/16 running and queued tasks[0m
[[34m2021-05-26 06:25:01,677[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 3/16 running and queued tasks[0m
[[34m2021-05-26 06:25:01,681[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 10:10:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:00:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2021-05-26 06:21:54.418538+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2021-05-26 06:22:57.868056+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:01,688[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 10, 10, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:25:01,689[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T10:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:01,689[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 10, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:01,689[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T10:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:01,696[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2021, 5, 26, 6, 21, 54, 418538, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:01,702[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2021-05-26T06:21:54.418538+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:01,702[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2021, 5, 26, 6, 22, 57, 868056, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:01,702[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2021-05-26T06:22:57.868056+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:01,721[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T10:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:03,951[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T10:10:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:04,977[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T10:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:07,485[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T10:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:08,306[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2021-05-26T06:21:54.418538+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:09,674[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2021-05-26T06:21:54.418538+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:10,335[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2021-05-26T06:22:57.868056+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:11,837[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2021-05-26T06:22:57.868056+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:12,678[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 10:10:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:12,679[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 10:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:12,679[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2021-05-26 06:21:54.418538+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:12,679[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2021-05-26 06:22:57.868056+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:12,860[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:10:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 10:20:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:12,874[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:25:12,876[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:25:12,878[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:25:12,880[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 10:20:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:10:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:12,885[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 10, 20, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:25:12,886[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T10:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:12,887[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 10, 10, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:12,888[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T10:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:12,896[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T10:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:14,440[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T10:20:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:15,216[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T10:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:16,573[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T10:10:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:17,315[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 10:20:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:17,315[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 10:10:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:17,581[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:20:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 10:30:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:17,586[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:25:17,588[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:25:17,589[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:25:17,590[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 10:30:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:20:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:17,596[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 10, 30, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:25:17,596[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T10:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:17,596[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 10, 20, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:17,597[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T10:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:17,608[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T10:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:19,071[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T10:30:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:19,764[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T10:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:21,186[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T10:20:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:21,887[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 10:30:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:21,888[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 10:20:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:22,040[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 10:00:00+00:00: scheduled__2018-09-24T10:00:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:25:22,052[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2021-05-26 06:21:54.418538+00:00: manual__2021-05-26T06:21:54.418538+00:00, externally triggered: True> failed[0m
[[34m2021-05-26 06:25:22,063[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2021-05-26 06:22:57.868056+00:00: manual__2021-05-26T06:22:57.868056+00:00, externally triggered: True> failed[0m
[[34m2021-05-26 06:25:22,095[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:30:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 10:40:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:22,099[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:25:22,101[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:25:22,102[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:25:22,104[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 10:40:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:30:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:22,112[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 10, 40, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:25:22,112[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T10:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:22,112[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 10, 30, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:22,112[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T10:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:22,120[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T10:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:23,696[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T10:40:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:24,409[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T10:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:25,813[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T10:30:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:26,449[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 10:40:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:26,449[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 10:30:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:26,584[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 10:10:00+00:00: scheduled__2018-09-24T10:10:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:25:26,614[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:40:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 10:50:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:26,617[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:25:26,619[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:25:26,620[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:25:26,622[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 10:50:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:40:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:26,629[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 10, 50, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:25:26,629[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T10:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:26,630[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 10, 40, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:26,630[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T10:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:26,638[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T10:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:28,010[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T10:50:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:28,716[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T10:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:30,049[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T10:40:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:30,645[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 10:50:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:30,646[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 10:40:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:30,794[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 10:20:00+00:00: scheduled__2018-09-24T10:20:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:25:30,824[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:50:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 11:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:30,831[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:25:30,834[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:25:30,835[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:25:30,837[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 11:00:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 10:50:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:30,844[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 11, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:25:30,844[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T11:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:30,844[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 10, 50, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:30,844[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T10:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:30,852[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T11:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:32,172[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T11:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:32,866[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T10:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:34,226[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T10:50:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:34,889[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 11:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:34,890[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 10:50:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:35,022[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 10:30:00+00:00: scheduled__2018-09-24T10:30:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:25:35,053[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 11:00:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 11:10:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:35,058[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:25:35,060[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:25:35,061[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:25:35,063[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 11:10:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 11:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:35,072[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 11, 10, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:25:35,072[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T11:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:35,072[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 11, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:35,072[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T11:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:35,083[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T11:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:36,477[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T11:10:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:37,243[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T11:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:38,665[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T11:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:39,343[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 11:10:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:39,344[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 11:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:39,502[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 10:40:00+00:00: scheduled__2018-09-24T10:40:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:25:39,529[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 11:10:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 11:20:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:39,533[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:25:39,534[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:25:39,536[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:25:39,537[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 11:20:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 11:10:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:39,543[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 11, 20, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:25:39,543[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T11:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:39,543[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 11, 10, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:39,544[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T11:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:39,552[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T11:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:41,038[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T11:20:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:41,756[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T11:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:43,142[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T11:10:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:43,832[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 11:20:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:43,833[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 11:10:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:43,933[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 10:50:00+00:00: scheduled__2018-09-24T10:50:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:25:43,956[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 11:20:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 11:30:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:43,958[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:25:43,958[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:25:43,958[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:25:43,958[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 11:30:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 11:20:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:43,961[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 11, 30, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:25:43,961[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T11:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:43,961[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 11, 20, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:43,962[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T11:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:43,972[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T11:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:45,380[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T11:30:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:46,086[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T11:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:47,506[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T11:20:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:48,130[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 11:30:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:48,131[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 11:20:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:48,406[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 11:00:00+00:00: scheduled__2018-09-24T11:00:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:25:48,432[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 11:30:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 11:40:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:48,434[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:25:48,434[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:25:48,434[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:25:48,434[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 11:40:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 11:30:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:48,439[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 11, 40, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:25:48,439[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T11:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:48,440[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 11, 30, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:48,440[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T11:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:48,447[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T11:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:49,828[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T11:40:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:50,531[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T11:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:51,943[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T11:30:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:52,742[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 11:40:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:52,742[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 11:30:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:52,883[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 11:10:00+00:00: scheduled__2018-09-24T11:10:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:25:52,910[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 11:40:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 11:50:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:52,922[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:25:52,924[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:25:52,925[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:25:52,927[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 11:50:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 11:40:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:52,933[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 11, 50, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:25:52,933[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T11:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:52,933[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 11, 40, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:52,934[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T11:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:52,944[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T11:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:54,349[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T11:50:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:55,211[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T11:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:56,639[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T11:40:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:57,256[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 11:50:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:57,256[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 11:40:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:25:57,426[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 11:20:00+00:00: scheduled__2018-09-24T11:20:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:25:57,449[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 11:50:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 12:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:57,451[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:25:57,452[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:25:57,452[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:25:57,452[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 12:00:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 11:50:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:25:57,456[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 12, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:25:57,457[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T12:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:57,457[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 11, 50, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:25:57,457[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T11:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:57,465[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T12:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:25:58,853[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T12:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:25:59,705[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T11:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:01,119[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T11:50:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:01,851[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 12:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:01,852[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 11:50:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:01,969[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 11:30:00+00:00: scheduled__2018-09-24T11:30:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:02,000[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 12:00:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 12:10:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:02,007[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:02,009[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:02,010[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:02,012[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 12:10:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 12:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:02,015[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 12, 10, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:02,016[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T12:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:02,016[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 12, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:02,016[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T12:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:02,026[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T12:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:03,546[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T12:10:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:04,326[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T12:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:05,685[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T12:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:06,459[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 12:10:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:06,459[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 12:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:06,607[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 11:40:00+00:00: scheduled__2018-09-24T11:40:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:06,631[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 12:10:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 12:20:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:06,634[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:06,634[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:06,635[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:06,635[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 12:20:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 12:10:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:06,639[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 12, 20, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:06,639[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T12:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:06,640[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 12, 10, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:06,640[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T12:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:06,650[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T12:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:08,081[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T12:20:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:08,879[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T12:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:10,333[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T12:10:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:11,009[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 12:20:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:11,010[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 12:10:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:11,162[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 11:50:00+00:00: scheduled__2018-09-24T11:50:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:11,193[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 12:20:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 12:30:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:11,198[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:11,199[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:11,201[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:11,202[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 12:30:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 12:20:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:11,207[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 12, 30, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:11,207[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T12:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:11,207[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 12, 20, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:11,208[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T12:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:11,218[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T12:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:12,890[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T12:30:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:13,701[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T12:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:15,224[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T12:20:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:16,006[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 12:30:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:16,007[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 12:20:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:16,161[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 12:00:00+00:00: scheduled__2018-09-24T12:00:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:16,197[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 12:30:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 12:40:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:16,202[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:16,204[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:16,206[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:16,207[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 12:40:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 12:30:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:16,211[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 12, 40, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:16,212[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T12:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:16,212[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 12, 30, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:16,212[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T12:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:16,221[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T12:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:17,603[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T12:40:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:18,325[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T12:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:19,712[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T12:30:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:20,387[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 12:40:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:20,388[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 12:30:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:20,631[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 12:10:00+00:00: scheduled__2018-09-24T12:10:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:20,678[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 12:40:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 12:50:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:20,687[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:20,690[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:20,694[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:20,695[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 12:50:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 12:40:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:20,698[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 12, 50, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:20,702[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T12:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:20,705[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 12, 40, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:20,706[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T12:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:20,729[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T12:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:22,299[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T12:50:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:23,152[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T12:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:24,517[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T12:40:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:25,309[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 12:50:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:25,310[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 12:40:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:25,455[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 12:20:00+00:00: scheduled__2018-09-24T12:20:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:25,492[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 12:50:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 13:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:25,496[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:25,497[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:25,498[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:25,500[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 13:00:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 12:50:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:25,509[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 13, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:25,510[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T13:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:25,510[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 12, 50, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:25,510[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T12:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:25,522[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T13:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:26,858[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T13:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:27,685[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T12:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:29,105[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T12:50:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:29,852[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 13:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:29,852[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 12:50:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:29,962[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 12:30:00+00:00: scheduled__2018-09-24T12:30:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:29,994[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 13:00:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 13:10:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:29,999[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:30,001[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:30,002[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:30,004[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 13:10:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 13:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:30,008[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 13, 10, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:30,008[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T13:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:30,008[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 13, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:30,008[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T13:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:30,018[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T13:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:31,336[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T13:10:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:32,060[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T13:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:33,414[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T13:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:34,120[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 13:10:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:34,121[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 13:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:34,276[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 12:40:00+00:00: scheduled__2018-09-24T12:40:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:34,303[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 13:10:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 13:20:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:34,307[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:34,309[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:34,311[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:34,313[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 13:20:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 13:10:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:34,316[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 13, 20, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:34,317[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T13:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:34,317[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 13, 10, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:34,317[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T13:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:34,326[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T13:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:35,716[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T13:20:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:36,480[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T13:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:37,853[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T13:10:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:38,544[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 13:20:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:38,545[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 13:10:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:38,676[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 12:50:00+00:00: scheduled__2018-09-24T12:50:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:38,697[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 13:20:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 13:30:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:38,700[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:38,700[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:38,700[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:38,701[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 13:30:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 13:20:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:38,704[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 13, 30, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:38,704[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T13:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:38,704[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 13, 20, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:38,705[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T13:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:38,714[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T13:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:40,093[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T13:30:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:40,871[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T13:20:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:42,457[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T13:20:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:43,248[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 13:30:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:43,249[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 13:20:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:43,404[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 13:00:00+00:00: scheduled__2018-09-24T13:00:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:43,435[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 13:30:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 13:40:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:43,440[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:43,442[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:43,443[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:43,445[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 13:40:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 13:30:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:43,450[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 13, 40, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:43,450[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T13:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:43,450[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 13, 30, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:43,450[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T13:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:43,461[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T13:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:45,064[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T13:40:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:45,856[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T13:30:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:47,444[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T13:30:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:48,254[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 13:40:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:48,255[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 13:30:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:48,389[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 13:10:00+00:00: scheduled__2018-09-24T13:10:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:48,418[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 13:40:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 13:50:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:48,425[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:48,427[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:48,428[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:48,429[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 13:50:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 13:40:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:48,437[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 13, 50, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:48,437[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T13:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:48,437[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 13, 40, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:48,438[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T13:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:48,446[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T13:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:49,879[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T13:50:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:50,708[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T13:40:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:52,104[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T13:40:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:52,962[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 13:50:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:52,962[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 13:40:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:53,198[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 13:20:00+00:00: scheduled__2018-09-24T13:20:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:53,231[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 13:50:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 14:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:53,236[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:53,245[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:53,247[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:53,249[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 14:00:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 13:50:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:53,255[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 14, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:53,255[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T14:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:53,256[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 13, 50, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:53,256[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T13:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:53,264[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T14:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:54,645[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T14:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:55,580[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T13:50:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:56,950[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T13:50:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:26:57,696[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 14:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:57,696[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 13:50:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:26:57,817[0m] {[34mdagrun.py:[0m429} ERROR[0m - Marking run <DagRun my_simple_dag @ 2018-09-24 13:30:00+00:00: scheduled__2018-09-24T13:30:00+00:00, externally triggered: False> failed[0m
[[34m2021-05-26 06:26:57,840[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 2 tasks up for execution:
	<TaskInstance: my_simple_dag.greet 2018-09-24 14:00:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 14:10:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:57,844[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2021-05-26 06:26:57,846[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:26:57,847[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag has 1/16 running and queued tasks[0m
[[34m2021-05-26 06:26:57,849[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag.say_Hi 2018-09-24 14:10:00+00:00 [scheduled]>
	<TaskInstance: my_simple_dag.greet 2018-09-24 14:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:26:57,855[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='say_Hi', execution_date=datetime.datetime(2018, 9, 24, 14, 10, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:26:57,856[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T14:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:57,856[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag', task_id='greet', execution_date=datetime.datetime(2018, 9, 24, 14, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:26:57,856[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T14:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:57,866[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'say_Hi', '2018-09-24T14:10:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:26:59,469[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.say_Hi 2018-09-24T14:10:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:27:00,351[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag', 'greet', '2018-09-24T14:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py'][0m
[[34m2021-05-26 06:27:01,901[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/test_dag.py[0m
Running <TaskInstance: my_simple_dag.greet 2018-09-24T14:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:27:02,577[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.say_Hi execution_date=2018-09-24 14:10:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:27:02,578[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag.greet execution_date=2018-09-24 14:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:28:01,450[0m] {[34mdag_processing.py:[0m404} WARNING[0m - DagFileProcessorManager (PID=16420) exited with exit code 1 - re-launching[0m
[[34m2021-05-26 06:28:01,459[0m] {[34mdag_processing.py:[0m254} INFO[0m - Launched DagFileProcessorManager with pid: 21030[0m
[[34m2021-05-26 06:28:01,473[0m] {[34msettings.py:[0m52} INFO[0m - Configured default timezone Timezone('UTC')[0m
[2021-05-26 06:28:01,500] {dag_processing.py:532} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2 ) when using sqlite. So we set parallelism to 1.
[[34m2021-05-26 06:30:01,408[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 06:34:58,614[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_simple_dag2.say_Hi 2021-05-25 00:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:34:58,616[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2021-05-26 06:34:58,617[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag2 has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:34:58,617[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag2.say_Hi 2021-05-25 00:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:34:58,620[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag2', task_id='say_Hi', execution_date=datetime.datetime(2021, 5, 25, 0, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:34:58,620[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'say_Hi', '2021-05-25T00:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:34:58,628[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'say_Hi', '2021-05-25T00:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:34:59,765[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py[0m
Running <TaskInstance: my_simple_dag2.say_Hi 2021-05-25T00:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:35:00,551[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag2.say_Hi execution_date=2021-05-25 00:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:35:00,655[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_simple_dag2.greet 2021-05-25 00:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:35:00,658[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2021-05-26 06:35:00,659[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag2 has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:35:00,659[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag2.greet 2021-05-25 00:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:35:00,664[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag2', task_id='greet', execution_date=datetime.datetime(2021, 5, 25, 0, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:35:00,664[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'greet', '2021-05-25T00:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:35:00,675[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'greet', '2021-05-25T00:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:35:01,980[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py[0m
Running <TaskInstance: my_simple_dag2.greet 2021-05-25T00:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:35:02,621[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag2.greet execution_date=2021-05-25 00:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:35:02,638[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 06:35:02,646[0m] {[34mscheduler_job.py:[0m1889} INFO[0m - Reset the following 1 orphaned TaskInstances:
	<TaskInstance: my_simple_dag2.sleep_me 2021-05-25 00:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:35:02,689[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_simple_dag2.sleep_me 2021-05-25 00:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:35:02,691[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2021-05-26 06:35:02,691[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag2 has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:35:02,691[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag2.sleep_me 2021-05-25 00:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:35:02,693[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag2', task_id='sleep_me', execution_date=datetime.datetime(2021, 5, 25, 0, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 2 and queue default[0m
[[34m2021-05-26 06:35:02,693[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'sleep_me', '2021-05-25T00:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:35:02,701[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'sleep_me', '2021-05-25T00:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:35:03,860[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py[0m
Running <TaskInstance: my_simple_dag2.sleep_me 2021-05-25T00:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:35:09,547[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag2.sleep_me execution_date=2021-05-25 00:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:35:09,729[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_simple_dag2.respond 2021-05-25 00:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:35:09,730[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2021-05-26 06:35:09,730[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag2 has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:35:09,730[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag2.respond 2021-05-25 00:00:00+00:00 [scheduled]>[0m
[[34m2021-05-26 06:35:09,743[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag2', task_id='respond', execution_date=datetime.datetime(2021, 5, 25, 0, 0, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 1 and queue default[0m
[[34m2021-05-26 06:35:09,744[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'respond', '2021-05-25T00:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:35:09,753[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'respond', '2021-05-25T00:00:00+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:35:11,045[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py[0m
Running <TaskInstance: my_simple_dag2.respond 2021-05-25T00:00:00+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:35:11,693[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag2.respond execution_date=2021-05-25 00:00:00+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:35:11,733[0m] {[34mdagrun.py:[0m444} INFO[0m - Marking run <DagRun my_simple_dag2 @ 2021-05-25 00:00:00+00:00: scheduled__2021-05-25T00:00:00+00:00, externally triggered: False> successful[0m
[[34m2021-05-26 06:37:34,592[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_simple_dag2.say_Hi 2021-05-26 06:37:33.844584+00:00 [scheduled]>[0m
[[34m2021-05-26 06:37:34,594[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2021-05-26 06:37:34,595[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag2 has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:37:34,595[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag2.say_Hi 2021-05-26 06:37:33.844584+00:00 [scheduled]>[0m
[[34m2021-05-26 06:37:34,598[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag2', task_id='say_Hi', execution_date=datetime.datetime(2021, 5, 26, 6, 37, 33, 844584, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 4 and queue default[0m
[[34m2021-05-26 06:37:34,598[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'say_Hi', '2021-05-26T06:37:33.844584+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:37:34,605[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'say_Hi', '2021-05-26T06:37:33.844584+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:37:35,664[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py[0m
Running <TaskInstance: my_simple_dag2.say_Hi 2021-05-26T06:37:33.844584+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:37:36,252[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag2.say_Hi execution_date=2021-05-26 06:37:33.844584+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:37:36,308[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_simple_dag2.greet 2021-05-26 06:37:33.844584+00:00 [scheduled]>[0m
[[34m2021-05-26 06:37:36,311[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2021-05-26 06:37:36,313[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag2 has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:37:36,314[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag2.greet 2021-05-26 06:37:33.844584+00:00 [scheduled]>[0m
[[34m2021-05-26 06:37:36,317[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag2', task_id='greet', execution_date=datetime.datetime(2021, 5, 26, 6, 37, 33, 844584, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 3 and queue default[0m
[[34m2021-05-26 06:37:36,317[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'greet', '2021-05-26T06:37:33.844584+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:37:36,326[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'greet', '2021-05-26T06:37:33.844584+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:37:37,530[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py[0m
Running <TaskInstance: my_simple_dag2.greet 2021-05-26T06:37:33.844584+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:37:38,197[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag2.greet execution_date=2021-05-26 06:37:33.844584+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:37:38,266[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_simple_dag2.sleep_me 2021-05-26 06:37:33.844584+00:00 [scheduled]>[0m
[[34m2021-05-26 06:37:38,268[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2021-05-26 06:37:38,269[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag2 has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:37:38,269[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag2.sleep_me 2021-05-26 06:37:33.844584+00:00 [scheduled]>[0m
[[34m2021-05-26 06:37:38,272[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag2', task_id='sleep_me', execution_date=datetime.datetime(2021, 5, 26, 6, 37, 33, 844584, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 2 and queue default[0m
[[34m2021-05-26 06:37:38,272[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'sleep_me', '2021-05-26T06:37:33.844584+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:37:38,280[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'sleep_me', '2021-05-26T06:37:33.844584+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:37:39,411[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py[0m
Running <TaskInstance: my_simple_dag2.sleep_me 2021-05-26T06:37:33.844584+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:37:45,093[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag2.sleep_me execution_date=2021-05-26 06:37:33.844584+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:37:45,381[0m] {[34mscheduler_job.py:[0m947} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_simple_dag2.respond 2021-05-26 06:37:33.844584+00:00 [scheduled]>[0m
[[34m2021-05-26 06:37:45,386[0m] {[34mscheduler_job.py:[0m981} INFO[0m - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2021-05-26 06:37:45,388[0m] {[34mscheduler_job.py:[0m1008} INFO[0m - DAG my_simple_dag2 has 0/16 running and queued tasks[0m
[[34m2021-05-26 06:37:45,391[0m] {[34mscheduler_job.py:[0m1069} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_simple_dag2.respond 2021-05-26 06:37:33.844584+00:00 [scheduled]>[0m
[[34m2021-05-26 06:37:45,398[0m] {[34mscheduler_job.py:[0m1111} INFO[0m - Sending TaskInstanceKey(dag_id='my_simple_dag2', task_id='respond', execution_date=datetime.datetime(2021, 5, 26, 6, 37, 33, 844584, tzinfo=Timezone('UTC')), try_number=1) to executor with priority 1 and queue default[0m
[[34m2021-05-26 06:37:45,398[0m] {[34mbase_executor.py:[0m82} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'respond', '2021-05-26T06:37:33.844584+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:37:45,407[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_simple_dag2', 'respond', '2021-05-26T06:37:33.844584+00:00', '--local', '--pool', 'default_pool', '--subdir', '/home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py'][0m
[[34m2021-05-26 06:37:46,538[0m] {[34mdagbag.py:[0m487} INFO[0m - Filling up the DagBag from /home/ubuntu/ML_cylynx_nlp/airflow/dags/__pycache__/test_dag.py[0m
Running <TaskInstance: my_simple_dag2.respond 2021-05-26T06:37:33.844584+00:00 [queued]> on host nus-fintech-ner-1.asia-southeast1-b.c.cylynx-dev-badc.internal
[[34m2021-05-26 06:37:47,132[0m] {[34mscheduler_job.py:[0m1212} INFO[0m - Executor reports execution of my_simple_dag2.respond execution_date=2021-05-26 06:37:33.844584+00:00 exited with status success for try_number 1[0m
[[34m2021-05-26 06:37:47,167[0m] {[34mdagrun.py:[0m444} INFO[0m - Marking run <DagRun my_simple_dag2 @ 2021-05-26 06:37:33.844584+00:00: manual__2021-05-26T06:37:33.844584+00:00, externally triggered: True> successful[0m
[[34m2021-05-26 06:40:02,685[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 06:45:02,721[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 06:50:02,756[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 06:55:02,788[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 07:00:02,824[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 07:05:02,859[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 07:10:02,896[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 07:15:02,931[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 07:20:02,966[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 07:25:03,004[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 07:30:03,044[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 07:35:03,078[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 07:40:03,112[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 07:45:03,148[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 07:50:03,185[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 07:55:03,220[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 08:00:03,252[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 08:05:03,287[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 08:10:03,330[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 08:15:03,364[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 08:20:03,382[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 08:25:03,416[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 08:30:03,448[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 08:35:03,485[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 08:40:03,520[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 08:45:03,553[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 08:50:03,587[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 08:55:03,622[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 09:00:03,655[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 09:05:03,687[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 09:10:03,721[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 09:15:03,757[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 09:20:03,792[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 09:25:03,825[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 09:30:03,859[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 09:35:03,899[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 09:40:03,934[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 09:45:03,968[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 09:50:04,001[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 09:55:04,033[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 10:00:04,066[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 10:05:04,101[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 10:10:04,136[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 10:15:04,170[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 10:20:04,204[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 10:25:04,239[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 10:30:04,283[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 10:35:04,317[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 10:40:04,352[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 10:45:04,388[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 10:50:04,419[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 10:55:04,451[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 11:00:04,487[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 11:05:04,506[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 11:10:04,540[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 11:15:04,576[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 11:20:04,610[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 11:25:04,644[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 11:30:04,679[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 11:35:04,715[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 11:40:04,748[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 11:45:04,783[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 11:50:04,816[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 11:55:04,851[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 12:00:04,885[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 12:05:04,921[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 12:10:04,955[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 12:15:04,990[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 12:20:05,025[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 12:25:05,058[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 12:30:05,093[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 12:35:05,192[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 12:40:05,225[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 12:45:05,258[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 12:50:05,291[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 12:55:05,325[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 13:00:05,359[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 13:05:05,395[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 13:10:05,428[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 13:15:05,460[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 13:20:05,494[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 13:25:05,527[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 13:30:05,560[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 13:35:05,593[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 13:40:05,624[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 13:45:05,646[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 13:50:05,679[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 13:55:05,712[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 14:00:05,751[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 14:05:05,797[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 14:10:05,850[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2021-05-26 14:15:05,894[0m] {[34mscheduler_job.py:[0m1822} INFO[0m - Resetting orphaned tasks for active dag runs[0m
